---
title: "Exercise 2 Jaeho Jang_Real"
author: "Jaeho Jang"
date: "3/30/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

```
###Q1
------------------------------------------------------------------
```{r echo = FALSE}
library(mosaic)
library(tidyverse)
library(FNN)
library(foreach)
```


##Lets split the dataset into two segments; 350 and 65 AmG
```{r echo = FALSE}
class350=subset(sclass,trim=='350')
class65amg=subset(sclass,trim=='65 AMG')
```
##for 350
##plot for relationship in price and mileage
```{r echo = FALSE}
plot(price~mileage,data=class350,main='350 price VS. mileage')
```
##Then derive the actual KNN by dividing into training and testing set for both 350 and 65 AMG trims

#split for the 350 class:
```{r echo = FALSE}
N350=nrow(class350)
N350_train=floor(0.8*N350)
N350_test=N350-N350_train

#Sample a index to include in training set
train350_ind=sample.int(N350,N350_train,replace=FALSE)

#Define the two sets
D350_train=class350[train350_ind,]
D350_test=class350[-train350_ind,]

#Seperate the two sets into features(mileage) and outcome(price)
X350_train=select(D350_train,mileage)
Y350_train=select(D350_train,price)
X350_test=select(D350_test,mileage)
Y350_test=select(D350_test,price)
```

#split for the 65 AMG class:
```{r echo = FALSE}
N65=nrow(class65amg)
N65_train=floor(0.8*N65)
N65_test=N65-N65_train
```
#Sample a index to include in training set
```{r echo = FALSE}
train65_ind=sample.int(N65,N65_train,replace=FALSE)

#Define the two sets

D65_train=class65amg[train65_ind,]
D65_test=class65amg[-train65_ind,]
#Seperate the two sets into features(mileage) and outcome(price)
X65_train=select(D65_train,mileage)
Y65_train=select(D65_train,price)
X65_test=select(D65_test,mileage)
Y65_test=select(D65_test,price)
```

##After, we run K neareest-neightbors for as much values as we need to, and for each K, we fit the model to the training set and make predictions on test set. Then, we calculate the RMSE for each K and generate a plot.
##This is the function for RMSE
```{r echo = FALSE}
rmse=function(y,ypred){
  sqrt(mean(data.matrix((y-ypred)^2)))
}
```
##Generate grids for the RMSE outputs for class 350
```{r echo = FALSE}
kgrid350=seq(3,100,by=2)
rmse_grid350=foreach(k=kgrid350,.combine='c')%do%{
  out=do(150)*{
    knn350_try=knn.reg(train=X350_train,test=X350_test,y=Y350_train,k=k)
    ypred350_knn_try=knn350_try$pred
    rmse(Y350_test,ypred350_knn_try)
  }
  mean(out$result)
}
plot(kgrid350,rmse_grid350,main="RMSE at every K for class 350")
```

##According to the RMSE vs. K plot, the optimal value is 16. Therefore, a plot of fitted model using K=16 is generated.
```{r echo = FALSE}
knn350_test=knn.reg(train=X350_train,test=X350_test,y=Y350_train,k=16)
ypred350_knn_test=knn350_test$pred
ggplot(data=D350_test)+
  geom_point(mapping=aes(x=mileage,y=price))+
  theme_bw(base_size=18)+
  ylim(500,120000)+
  labs(title='Fitted Model for 350 at K=16')
```

##Generate gride for the RMSE outputs for class 65 AMG
```{r echo = FALSE}
plot(price~mileage,data=class65amg,main='65 AMG price VS. mileage')

kgrid65=seq(3,100,by=2)
rmse_grid65=foreach(k=kgrid65,.combine='c')%do%{
  out=do(150)*{
    knn65_try=knn.reg(train=X65_train,test=X65_test,y=Y65_train,k=k)
    ypred65_knn_try=knn65_try$pred
    rmse(Y65_test,ypred65_knn_try)
  }
  mean(out$result)
}
plot(kgrid65,rmse_grid65,main="RMSE at every K for class 65AMG")
```

##According to the RMSE vs. K plot, the optimal value is 33. Therefore, a plot of fitted model using K=33 is generated.
```{r echo = FALSE}
knn65_test=knn.reg(train=X65_train,test=X65_test,y=Y65_train,k=16)
ypred65_knn_test=knn65_test$pred
ggplot(data=D65_test)+
  geom_point(mapping=aes(x=mileage,y=price))+
  theme_bw(base_size=18)+
  ylim(200,250000)+
  labs(title='Fitted Model for 65 AMG at K=33')
```

##Looking at the price vs. mileage plots, it can be told that both 350 class and 65 AMG class maintain a higher price when the mileage is low; highly concentrated with low variation. According to the RMSE vs. K plots, it looks like 65 AMG yields a higher optimal value of K than that of the 350 class.In conclusion, this means that the 65 AMG class must have a higher K value to minize RMSE, and therefore, deal with prices that vary more greatly.

###Q2
------------------------------------------------------------------
```{r echo = FALSE}
library(mosaic)
library(tidyverse)
library(FNN)
data(SaratogaHouses)
```

#Firstly, it was evident that in the existing 'medium' model, the used features were not sufficient enough to grasp a greater, broader understanding about the relationship between prices and characteristics of houses in Saratoga, New York. That being said, it seemed probable to include all the feautres in the Saratoga houses model to clear capture what the model tells us and gain a more accurate understanding about the existing relationship between price and houses' characteristics.
#So therefore, we decided to include all feautres in the linear model.

#Define the RMSE function
```{r echo = FALSE}
rmse=function(y,ypred){
  sqrt(mean(data.matrix((y-ypred)^2)))
}
```

#Define the training and test set
```{r echo = FALSE}
nhouses=nrow(SaratogaHouses)
houses_train=floor(0.8*houses)
houses_test=houses-houses_train

housing_ind=sample.int(nhouses,houses_train,replace=FALSE)

Dhouse_train=SaratogaHouses[housing_ind,]
Dhouse_test=SaratogaHouses[-housing_ind,]
```

#Creates 200 different splits to see variation
```{r echo = FALSE}
rmse_Sarahouses=do(200)*{
  #existing medium model
  lm_medium = lm(price~lotSize+age+livingArea+pctCollege+bedrooms+ 
                   fireplaces+bathrooms+rooms+heating+fuel+centralAir,data=Dhouse_train)
  lm_new=lm(price~.,data=Dhouse_train)

  #Predictions from both models
  med_test=predict(lm_medium,Dhouse_test)
  new_test=predict(lm_new,Dhouse_test)
  
  c(rmse(Dhouse_test$price,med_test),
    rmse(Dhouse_test$price,new_test))
}

```

#Compare the new model's average error against that of medium model
```{r echo = FALSE}
means=colMeans(rmse_Sarahouses)
print(means[1])
print(means[2])
```

#This shows that the new linear model - with a lower average error - already performs better than the existing model. However, it seems reasonable to check the KNN model and compare it with the linear and discover which model performs better.

#Fit the model for Ks' in the new model
```{r echo = FALSE}
k_range=2:25
rmse_vals=matrix(0,24,2)

#Create loop generate KNN model
for (k_val in k_range){
  rmse_vals_loop=do(200)*{
    Xhouse_train=model.matrix(price~.-1,data=Dhouse_train)
    Xhouse_test=model.matrix(price~.-1,data=Dhouse_test)
    Yhouse_train=Dhouse_train$price
    Yhouse_test=Dhouse_test$price
    
    #standardize data
    scale_amt=apply(Xhouse_train,2,sd)
    Xhouse_train=scale(Xhouse_train,scale=scale_amt)
    Xhouse_test=scale(Xhouse_test,scale=scale_amt)
    
    #Generate K model
    house_model=knn.reg(Xhouse_train,Xhouse_test,Yhouse_train,k=k_val)
    
    #Prediction on K model
    c(rmse(Yhouse_test,house_model$pred),
      means[2])
  }
  #Compare ? of models
  val_avg=colMeans(rmse_vals_loop)
  rmse_vals[k_val-1,1]=val_avg[1]
  rmse_vals[k_val-1,2]=val_avg[2]

}
```

#plot the RMSE vs K model
```{r echo = FALSE}
err=rmse_vals[,1]
ggplot(data=data.frame(k_range,err))+
  geom_point(mapping=aes(x=k_range,y=err))+
  labs(title="RMSE vs. K")+
  geom_text(aes(0,min(err),label = paste(which.min(err), " error: ", round(min(err)))))
```
#The optimal K value seems to exist at K=10 with error of 60909.5.

## However, comparing the linear model and the KNN model, KNN model seems to have a higher average error value. This may be due to the difference in how effective each variable (characteristics) are to price; price may be more sensitive to some variable than others and standardizing fails to recognize this. Nonetheless, in the end, the city is recommend to use either of the two new model over the existing medium model.

###Q3
------------------------------------------------------------------
```{r echo = FALSE}
library(mosaic)
library(tidyverse)
```

##First, lets approach the Regression modeling approach (regression first and threshold second method). 
##I chose to begin with linear modeling and chose to include all features - due to similar reason on Q2- were selected in the data model to get a better understanding of the general picture of dataset.
#split the train and test sets
```{r echo = FALSE}
nNews=nrow(online_news)
news_train=floor(0.8*nNews)
news_test=nNews-news_train
```

#200 random splits conducted
```{r echo = FALSE}
splits_lm=do(200)*{
  #make sure that averages are split across multiple splits
  news_ind=sample.int(nNews,news_train,replace=FALSE)
  Dnews_train=online_news[news_ind,ncol(online_news)]
  Dnews_test=online_news[-news_ind,ncol(online_news)]
  lm_news=lm(shares~.,data=Dnews_train)
  
  #Code for binary output statements
  predict_news=predict(lm_news,Dnews_test)
  greater_news=ifelse(predict_news>1400,1,0)
  binary_news=ifelse(Dnews_test$shares>1400,1,0)
  
  #Prompt the confusion matrix, error rate, true positive rate, false positive rate and calculate them
  conf_mat=table(greater=binary_news,binary=greater_news)
  err_rate=(conf_mat[2]+conf_mat[3])/sum(conf_mat)
  tru_pos_rate=conf_mat[4]/(conf_mat[2]+conf_mat[4])
  fal_pos_rate=conf_mat[3]/(conf_mat[1]+conf_mat[3])
  
  c(conf_mat,err_rate,tru_pos_rate,fal_pos_rate)
}
avg_val=colMeans(splits_lm)
```

#print the 4 features
```{r echo = FALSE}
print("Confusion Matrix:")
print((paste(avg_val[1]," ",avg_val[3])))
print((paste(avg_val[2]," ",avg_val[4])))
print(paste("Overall Error Rate:",avg_val[5]))
print(paste("True Positive Rate:",avg_val[6]))
print(paste("False Positive Rate:",avg_val[7]))
```

##Next, lets approach the Classification modeling approach (threshhold first and regress later).
##With the Classification method, I chose the logistic model to distinctly show the difference from the linear regression model.
```{r echo = FALSE}
vals_lm_log=do(200)*{
  news_ind=sample.int(nNews,news_train,replace=FALSE)
  Dnews_train=online_news[news_ind,ncol(online_news)]
  Dnews_test=online_news[-news_ind,ncol(online_news)]
  
  #make binary decision structure for the output
  Dnews_train$viral=ifelse(Dnews_train$shares>1400,1,0)
  Dnews_test$viral=ifelse(Dnews_test$shares>1400,1,0)
  lm_log=glm(viral~.,data=Dnews_train,family=binomial,maxit=100)
  #Predictions from the sample that converts into a binary output
  binary_pred=predict(lm_log,Dnews_test,type='response')
  binary_out=ifelse(binary_pred>0.5,1,0)
  binary=Dnews_test$viral
  #Calculate confusion matrix, error rate, true positive rate, false positive rate
  conf_mat=table(x=binary,y=binary_out)
  err_rate=(conf_mat[2]+conf_mat[3])/sum(conf_mat)
  tru_pos_rate=conf_mat[4]/(conf_mat[2]+conf_mat[4])
  fal_pos_rate=conf_mat[3]/(conf_mat[1]+conf_mat[3])
  
  c(conf_mat,err_rate,tru_pos_rate,fal_pos_rate)
}
avg_val_log=colMeans(vals_lm_log)
```

#print the 4 features
```{r echo = FALSE}
print("Confusion Matrix: ")
print(paste(avg_val_log[1]," ",avg_val_log[3]))
print(paste(avg_val_log[2]," ",avg_val_log[4]))
print(paste("Overall Error Rate:", avg_val_log[5]))
print(paste("True Positive Rate:", avg_val_log[6]))
print(paste("False Positive Rate:",avg_val_log[7]))
```
